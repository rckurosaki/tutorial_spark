# 1. Sobre

Apache Spark™ é um sistema de processamento distribuído de código aberto usado para *big data*. Ele permite que você processe conjuntos grandes de dados mais rapidamente, dividindo o trabalho em partes e atribuindo essas partes aos recursos computacionais.

Os pontos que ditam o que é o Spark basicamente são rapidez, generalidade, facilidade de uso e fácil integração, pois trabalha com diversas bases de dados e sitemas que vem a cabeça quando se trata de dados.

Ele nasceu para ser mais rápido do que as abordagens anteriores que trabalham com *big data* como o MapReduce clássico do Hadoop. O segredo de ser mais rápido é que o Spark roda *in-memory* , o que torna o processamento muito mais rápido do que nas unidades de disco.

A generalidade significa que ele pode ser usado para várias coisas, como executar SQL distribuído, criar *pipelines* de dados, carregar dados em um banco de dados SQL ou NOSQL, executar algoritmos de aprendizado de máquina, trabalhar com gráficos ou fluxos de dados e muito mais.

Facilidade de uso, o Spark oferece mais de 80 operadores de alto nível que facilitam a construção de *pipelines* nas linguagens Java, Scala, Python, R e SQL. E você pode usá-lo interativamente a partir dos *shells* Scala, Python, R e SQL.
